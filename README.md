# CourtRoomSimulation

Created an agentic simulation engine that reaches the accurate verdict through iterative reasoning 

### Structure

Router LLM -> Roleplay LLM -> Router LLM

Router LLM is responsible for 3 things
1. Analyses the conversation to decide which agent to call next (witness, judge etc)
2. Generates a character description for this agent, which will be created
3. Decides the phase of the simulation ie (opening statements, verdict etc)

Roleplay LLM is resposible for taking in the character description as its system prompt and then outputing the dialogue for the scene.

### Context Window
A dynamic context window is implemented such that for every message appended to the window one message is forgotten (except the system prompt) after a 
certain lenght. The case summary generated by a summary LLM is inside the system prompt itself to avoid straying away from the original case. This also
helps in reasoning as rather than analysing the entire context and generating a narration or story, it builds upon the last few messages.

### Code Description
1. `main.py` : main file for the agentic system\n
2. `utils.py`: contains all the utility function used in the simulator
3. `spam.py`: code file used to generate results on the kaggle competiton due to time constraint
4. `preprocess.py` : code file used to combine two dataframes, as id 34 had a larger context window then permitted, leading to fragmentation in the outputs

### Outputs and others
1. `roleplay_init_prompt.txt` : base system prompt for the roleplay LLM
2. `router_prompt_new.txt`: base system primpt for the router LLM
3. `spam.csv`: Output as used in the kaggle competion generated by the spam.py
4. `transcript.json`: A json file to analyse the output transcript

### Running the Code
All API Keys are blank so you will be manually required to input the api key in the groq client wherever require. Will change this to exporting from the env in the next commit
